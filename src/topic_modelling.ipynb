{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1332639c-300c-474f-9293-361201190cab",
   "metadata": {},
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa23355-cba1-4d46-9e05-f81db061ff77",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de8f2537-b9b5-4349-8eff-a91471adb444",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cindy/opt/anaconda3/lib/python3.8/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "import pyLDAvis.gensim_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93accbff-dd03-4d71-bb69-e9d061f4bba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/cindy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Load NLTK tools\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822da4f0-132e-4986-998d-7be4ca7ea166",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2580fc2-a164-42ae-938b-1f54295d5b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_folder = '../data/'\n",
    "df = pd.read_csv(data_folder + 'scraped_data.csv')\n",
    "transcript_df = pd.DataFrame(df['transcript'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1761932d-4fa1-4cc6-9176-3c9107010a67",
   "metadata": {},
   "source": [
    "## Text Processing: NLP pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "962c34ac-8997-40dc-975e-13b6bad310fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "transcript_df['tokenized'] = df['transcript'].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6303000-6612-48ad-b872-094e3c8de134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS + NER\n",
    "def extract_ne(token_list: list, entity_list=[\"PERSON\"]) -> set:\n",
    "    entity_set = set(entity_list)\n",
    "    tags = nltk.pos_tag(token_list)\n",
    "    tree = nltk.ne_chunk(tags, binary=False)\n",
    "    return set(\n",
    "        \" \".join(i[0] for i in t)\n",
    "        for t in tree\n",
    "        if hasattr(t, \"label\") and t.label() in entity_set\n",
    "     )\n",
    "transcript_df['NER'] = transcript_df['tokenized'].apply(extract_ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edcd07af-c520-40db-8d3d-317ca5e7b562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stopwords and Casefolding\n",
    "transcript_df['no_stopwords'] = transcript_df['tokenized'].apply(\n",
    "    lambda l: [s.casefold() for s in l if s.casefold() not in stop_words and s not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50fd612c-f5f0-4cba-86ff-1411d29889ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "transcript_df['lemmatized'] = transcript_df['no_stopwords'].apply(\n",
    "    lambda l: [lemmatizer.lemmatize(s) for s in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e12bbb7f-1373-493f-9b17-152a36b7c53e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>NER</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cindy Kelly: This is Wednesday, March 20. Inge...</td>\n",
       "      <td>[Cindy, Kelly, This, is, Wednesday, March, 20,...</td>\n",
       "      <td>{Kip Thorne, Willy, Sackmann Christy, Robert, ...</td>\n",
       "      <td>[cindy, kelly, wednesday, march, 20, inge, jul...</td>\n",
       "      <td>[cindy, kelly, wednesday, march, 20, inge, jul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trisha Pritikin: Okay. It is January 15th, 20...</td>\n",
       "      <td>[Trisha, Pritikin, Okay, It, is, January, 15th...</td>\n",
       "      <td>{Columbia River, Foulds Yes Dorn Steele, Ellis...</td>\n",
       "      <td>[trisha, pritikin, okay, january, 15th, 2019, ...</td>\n",
       "      <td>[trisha, pritikin, okay, january, 15th, 2019, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Karen Dorn Steele: Our second interview is wit...</td>\n",
       "      <td>[Karen, Dorn, Steele, Our, second, interview, ...</td>\n",
       "      <td>{Dusty Washington, Tom, Ellis, William Etter, ...</td>\n",
       "      <td>[karen, dorn, steele, second, interview, richa...</td>\n",
       "      <td>[karen, dorn, steele, second, interview, richa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Karen Dorn Steele: It’s April 29, 2019. Our fi...</td>\n",
       "      <td>[Karen, Dorn, Steele, It, s, April, 29, 2019, ...</td>\n",
       "      <td>{Cook Well, Cook Pigford, Robert, Hazel R, Ph,...</td>\n",
       "      <td>[karen, dorn, steele, april, 29, 2019, first, ...</td>\n",
       "      <td>[karen, dorn, steele, april, 29, 2019, first, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The Atomic Heritage Foundation is very gratef...</td>\n",
       "      <td>[The, Atomic, Heritage, Foundation, is, very, ...</td>\n",
       "      <td>{Guise PH, Mother George Oh, Mark Yeah, Mark, ...</td>\n",
       "      <td>[atomic, heritage, foundation, grateful, mark,...</td>\n",
       "      <td>[atomic, heritage, foundation, grateful, mark,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          transcript  \\\n",
       "0  Cindy Kelly: This is Wednesday, March 20. Inge...   \n",
       "1   Trisha Pritikin: Okay. It is January 15th, 20...   \n",
       "2  Karen Dorn Steele: Our second interview is wit...   \n",
       "3  Karen Dorn Steele: It’s April 29, 2019. Our fi...   \n",
       "4  [The Atomic Heritage Foundation is very gratef...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [Cindy, Kelly, This, is, Wednesday, March, 20,...   \n",
       "1  [Trisha, Pritikin, Okay, It, is, January, 15th...   \n",
       "2  [Karen, Dorn, Steele, Our, second, interview, ...   \n",
       "3  [Karen, Dorn, Steele, It, s, April, 29, 2019, ...   \n",
       "4  [The, Atomic, Heritage, Foundation, is, very, ...   \n",
       "\n",
       "                                                 NER  \\\n",
       "0  {Kip Thorne, Willy, Sackmann Christy, Robert, ...   \n",
       "1  {Columbia River, Foulds Yes Dorn Steele, Ellis...   \n",
       "2  {Dusty Washington, Tom, Ellis, William Etter, ...   \n",
       "3  {Cook Well, Cook Pigford, Robert, Hazel R, Ph,...   \n",
       "4  {Guise PH, Mother George Oh, Mark Yeah, Mark, ...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  [cindy, kelly, wednesday, march, 20, inge, jul...   \n",
       "1  [trisha, pritikin, okay, january, 15th, 2019, ...   \n",
       "2  [karen, dorn, steele, second, interview, richa...   \n",
       "3  [karen, dorn, steele, april, 29, 2019, first, ...   \n",
       "4  [atomic, heritage, foundation, grateful, mark,...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  [cindy, kelly, wednesday, march, 20, inge, jul...  \n",
       "1  [trisha, pritikin, okay, january, 15th, 2019, ...  \n",
       "2  [karen, dorn, steele, second, interview, richa...  \n",
       "3  [karen, dorn, steele, april, 29, 2019, first, ...  \n",
       "4  [atomic, heritage, foundation, grateful, mark,...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "898743a5-e2cf-454d-93dc-c7123b0ec974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the processed transcripts to a csv file\n",
    "transcript_df.to_csv(data_folder + 'processed_transcripts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64107c03-c900-49e4-af28-2830b0761c91",
   "metadata": {},
   "source": [
    "## Bag of Words (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40f388aa-0b5b-4e4e-a1bb-2bfd39b3549a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a gensim dictionary\n",
    "dictionary = Dictionary(transcript_df['lemmatized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1311b775-6550-4c2d-a591-3c2c2c3636e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bag-of-words representation of the documents\n",
    "corpus = [dictionary.doc2bow(text) for text in transcript_df['lemmatized']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e8c0c0-a67b-4e0d-bd9b-304be85309ad",
   "metadata": {},
   "source": [
    "## Topic Modelling: LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b30ccc43-f4a6-440d-a05a-492e9fe4a095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an LDA model on the corpus\n",
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ea8b676-8bab-4ef5-a4e2-b0892bbe9268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cindy/opt/anaconda3/lib/python3.8/site-packages/pyLDAvis/_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    }
   ],
   "source": [
    "# Visualize the results using pyLDAvis\n",
    "pyLDAvis.enable_notebook()\n",
    "vis_data = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\n",
    "pyLDAvis.save_html(vis_data, '../results/topic_modeling.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c0b7e5-04af-4448-a9f2-f3c67058a4d3",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
