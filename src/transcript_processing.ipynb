{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a58cd6b-2df5-4a69-9fd6-e94687f2d1e7",
   "metadata": {},
   "source": [
    "# Transcript Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8170f9d4-9396-4424-a081-df397896c755",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a74f49e1-26fc-4ca5-9173-b2e48d856a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cindy/opt/anaconda3/lib/python3.8/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07ec22c8-7308-44b5-aafb-6576f472210a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/cindy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Load NLTK tools\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c60439-8811-4865-b998-f75923b7f8ce",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19505a90-366e-4f71-bd91-db4042bcf349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_folder = '../data/'\n",
    "df = pd.read_csv(data_folder + 'scraped_data.csv')\n",
    "transcript_df = pd.DataFrame(df['transcript'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8549d581-dc88-4a75-bab1-7e4435c0388f",
   "metadata": {},
   "source": [
    "## Text Processing: NLP pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "426a5c45-c8fd-4681-8d45-8196af7f3477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "transcript_df['tokenized'] = df['transcript'].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccbd6370-04da-4474-9bbf-5981d18bdeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS + NER\n",
    "def extract_ne(token_list: list, entity_list=[\"PERSON\"]) -> set:\n",
    "    entity_set = set(entity_list)\n",
    "    tags = nltk.pos_tag(token_list)\n",
    "    tree = nltk.ne_chunk(tags, binary=False)\n",
    "    return set(\n",
    "        \" \".join(i[0] for i in t)\n",
    "        for t in tree\n",
    "        if hasattr(t, \"label\") and t.label() in entity_set\n",
    "     )\n",
    "transcript_df['NER'] = transcript_df['tokenized'].apply(extract_ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45e25bb3-d286-4dfb-9c9f-c4c08bf43014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stopwords and Casefolding\n",
    "transcript_df['no_stopwords'] = transcript_df['tokenized'].apply(\n",
    "    lambda l: [s.casefold() for s in l if s.casefold() not in stop_words and s not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60eefca5-82db-4b93-9167-96f511ab4135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "transcript_df['lemmatized'] = transcript_df['no_stopwords'].apply(\n",
    "    lambda l: [lemmatizer.lemmatize(s) for s in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6648c986-d90e-4993-9b76-05663a413088",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>NER</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cindy Kelly: This is Wednesday, March 20. Inge...</td>\n",
       "      <td>[Cindy, Kelly, This, is, Wednesday, March, 20,...</td>\n",
       "      <td>{Kip Thorne, Willy, Sackmann Christy, Robert, ...</td>\n",
       "      <td>[cindy, kelly, wednesday, march, 20, inge, jul...</td>\n",
       "      <td>[cindy, kelly, wednesday, march, 20, inge, jul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trisha Pritikin: Okay. It is January 15th, 20...</td>\n",
       "      <td>[Trisha, Pritikin, Okay, It, is, January, 15th...</td>\n",
       "      <td>{Columbia River, Foulds Yes Dorn Steele, Ellis...</td>\n",
       "      <td>[trisha, pritikin, okay, january, 15th, 2019, ...</td>\n",
       "      <td>[trisha, pritikin, okay, january, 15th, 2019, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Karen Dorn Steele: Our second interview is wit...</td>\n",
       "      <td>[Karen, Dorn, Steele, Our, second, interview, ...</td>\n",
       "      <td>{Dusty Washington, Tom, Ellis, William Etter, ...</td>\n",
       "      <td>[karen, dorn, steele, second, interview, richa...</td>\n",
       "      <td>[karen, dorn, steele, second, interview, richa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Karen Dorn Steele: It’s April 29, 2019. Our fi...</td>\n",
       "      <td>[Karen, Dorn, Steele, It, s, April, 29, 2019, ...</td>\n",
       "      <td>{Cook Well, Cook Pigford, Robert, Hazel R, Ph,...</td>\n",
       "      <td>[karen, dorn, steele, april, 29, 2019, first, ...</td>\n",
       "      <td>[karen, dorn, steele, april, 29, 2019, first, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The Atomic Heritage Foundation is very gratef...</td>\n",
       "      <td>[The, Atomic, Heritage, Foundation, is, very, ...</td>\n",
       "      <td>{Guise PH, Mother George Oh, Mark Yeah, Mark, ...</td>\n",
       "      <td>[atomic, heritage, foundation, grateful, mark,...</td>\n",
       "      <td>[atomic, heritage, foundation, grateful, mark,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          transcript  \\\n",
       "0  Cindy Kelly: This is Wednesday, March 20. Inge...   \n",
       "1   Trisha Pritikin: Okay. It is January 15th, 20...   \n",
       "2  Karen Dorn Steele: Our second interview is wit...   \n",
       "3  Karen Dorn Steele: It’s April 29, 2019. Our fi...   \n",
       "4  [The Atomic Heritage Foundation is very gratef...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [Cindy, Kelly, This, is, Wednesday, March, 20,...   \n",
       "1  [Trisha, Pritikin, Okay, It, is, January, 15th...   \n",
       "2  [Karen, Dorn, Steele, Our, second, interview, ...   \n",
       "3  [Karen, Dorn, Steele, It, s, April, 29, 2019, ...   \n",
       "4  [The, Atomic, Heritage, Foundation, is, very, ...   \n",
       "\n",
       "                                                 NER  \\\n",
       "0  {Kip Thorne, Willy, Sackmann Christy, Robert, ...   \n",
       "1  {Columbia River, Foulds Yes Dorn Steele, Ellis...   \n",
       "2  {Dusty Washington, Tom, Ellis, William Etter, ...   \n",
       "3  {Cook Well, Cook Pigford, Robert, Hazel R, Ph,...   \n",
       "4  {Guise PH, Mother George Oh, Mark Yeah, Mark, ...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  [cindy, kelly, wednesday, march, 20, inge, jul...   \n",
       "1  [trisha, pritikin, okay, january, 15th, 2019, ...   \n",
       "2  [karen, dorn, steele, second, interview, richa...   \n",
       "3  [karen, dorn, steele, april, 29, 2019, first, ...   \n",
       "4  [atomic, heritage, foundation, grateful, mark,...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  [cindy, kelly, wednesday, march, 20, inge, jul...  \n",
       "1  [trisha, pritikin, okay, january, 15th, 2019, ...  \n",
       "2  [karen, dorn, steele, second, interview, richa...  \n",
       "3  [karen, dorn, steele, april, 29, 2019, first, ...  \n",
       "4  [atomic, heritage, foundation, grateful, mark,...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fea808e-0f95-4033-8043-1e0a4ec02eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the processed transcripts to a csv file\n",
    "transcript_df.to_csv(data_folder + 'processed_transcripts.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
